
########################
# Common config

# JMS Broker Configuration
jms.broker.host.name=servername.ebi.ac.uk
jms.broker.port.number=5445

# Embedded JMS Broker Configuration
broker.directory=broker_data

# JDBC Configuration
i5.database.driverClassName=org.h2.Driver
i5.database.driverJar=
i5.database.connection.url=jdbc:h2:mem:interpro;LOCK_TIMEOUT=10000
i5.database.username=sa
i5.database.password=

#Clean database installation (only used by embedded master)

i5.h2.database.original.location=temp/template/interpro.zip

# Hibernate Configuration
#hibernate.dialect=org.hibernate.dialect.H2Dialect
hibernate.dialect=org.hibernate.dialect.HSQLDialect
hibernate.show_sql=false
hibernate.format_sql=true
hibernate.default_schema=PUBLIC
hibernate.use_sql_comments=false
hibernate.jdbc.batch_size=30
hibernate.hbm2ddl_auto=create

########################
# Master config

unix.username=username

########################
# Worker config


temporary.file.directory=temp/[UNIQUE]
jvm.maximum.idle.time.seconds=120
jvm.maximum.life.seconds=7200

# /ebi/sp/pro1/interpro/binaries/scripts/ps_scan.pl -d /ebi/production/interpro/data/members/hamap/180510/hamap.prf --pfscan /ebi/sp/pro1/interpro/binaries/64_bit_Linux/pfscan -l -1 -o gff

# Configure the version of perl to use when running member databases perl binaries
perl.command=perl

# Binary file locations
binary.hmmer3.hmmscan.path=bin/hmmscan
binary.hmmer3.hmmsearch.path=bin/hmmsearch
binary.hmmer2.hmmsearch.path=bin/hmmer/hmmer2/hmmsearch
binary.hmmer2.hmmpfam.path=bin/hmmpfam
binary.phobius.pl.path.1.01=bin/phobius/1.01/phobius.pl
binary.fingerprintscan.path=bin/fingerPRINTScan
domainfinder3.path=bin/DomainFinder3
binary.coils.path=bin/ncoils
binary.prodom.2006.1.prodomblast3i.pl.path=bin/prodom/2006.1/ProDomBlast3i.pl
binary.prosite.psscan.pl.path=bin/ps_scan.pl
binary.prosite.pfscan.path=bin/pfscan
binary.panther.path=bin/panther/7.0/pantherScore.pl
binary.superfamily.1.75.ass3.pl.path=bin/superfamily/1.75/ass3.pl
binary.blastall.2.2.6.path=bin/blast/2.2.6/blastall
binary.blast.2.2.19.path=bin/blast/2.2.19
binary.getorf.path=bin/nucleotide/getorf
binary.signalp.4.0.path=
binary.tmhmm.path=bin/tmhmm/2.0c/decodeanhmm

# Member database specific configuration
Pfam-A.hmm.path.24.0=data/pfam/24.0/Pfam-A.hmm
Pfam-A.seed.path.24.0=data/pfam/24.0/Pfam-A.seed
Pfam-C.path.24.0=data/pfam/24.0/Pfam-C
gene3d.hmm.path.3.3.0=data/gene3d/3.3.0/cath_v3_3_0.lib
gene3d.model2sf_map.path.3.3.0=data/gene3d/3.3.0/model2sf_map.csv
prints.kdat.path.41.1=data/prints/41.1/prints40_1.kdat
prints.pval.path.41.1=data/prints/41.1/prints.pval
prints.hierarchy.path.41.1=data/prints/41.1/FingerPRINTShierarchy.db
coils.new_coil.mat.path.2.2=data/coils/2.2/new_coil.mat
hamap.profile.models.path.180510=data/hamap/180510/hamap.prf
pirsf.hmm.bin.path.2.74=data/pirsf/2.74/sf_hmm.bin
pirsf.hmm.path.2.74=data/pirsf/2.74/sf_hmm
pirsf.dat.path.2.74=data/pirsf/2.74/pirsf.dat
pirsf.sf.tb.path.2.74=data/pirsf/2.74/sf.tb
pirsf.sf.seq.path.2.74=data/pirsf/2.74/sf.seq
prodom.ipr.path.2006.1=data/prodom/2006.1/prodom.ipr
#prodom.binary.tmp.path.2006.1=/tmp
prosite.models.path.20.66=data/prosite/20.66/prosite.dat
prosite.evaluator.models.path.20.66=data/prosite/20.66/evaluator.dat
tigrfam.hmm.path.9.0=data/tigrfam/9.0/TIGRFAMs_9.0_HMM.LIB
tigrfam.hmm.bin.path.9.0=data/tigrfam/9.0/TIGRFAMs_9.0_HMM.LIB.bin
tigrfam.hmm.path.10.1=data/tigrfam/10.1/TIGRFAMs_10.1_HMM.LIB
smart.hmm.path.6.1=data/smart/6.1/smart.HMMs
smart.hmm.bin.path.6.1=data/smart/6.1/smart.HMMs.bin
smart.overlapping.path=data/smart/6.1/overlapping
smart.threshold.path=data/smart/6.1/THRESHOLD
panther.perl.library=data/panther/7.0/perllib
superfamily.hmm.path.3.0=data/superfamily/1.75/hmmlib_1.75
superfamily.self.hits.path.1.75=data/superfamily/1.75/self_hits.tab
superfamily.cla.path.1.75=data/superfamily/1.75/dir.cla.scop.txt_1.75
superfamily.model.tab.path.1.75=data/superfamily/1.75/model.tab
superfamily.pdbj95d.path.1.75=data/superfamily/1.75/pdbj95d
tmhmm.model.version=2.0
tmhmm.model.path=data/tmhmm/model/${tmhmm.model.version}/TMHMM${tmhmm.model.version}.model

# These values control the maximum number of proteins put through
# an analysis in one go - different algorithms have different optimum values.
# Note that if you suffer from out of memory errors, reducing these values
# will almost certainly help, but may reduce the speed of analysis.
analysis.max.sequence.count.SIGNALP=600
analysis.max.sequence.count.TMHMM=1000
analysis.max.sequence.count.PANTHER=500
analysis.max.sequence.count.SMART=50
analysis.max.sequence.count.TIGRFAM_9=50
analysis.max.sequence.count.TIGRFAM_10=5000
analysis.max.sequence.count.GENE3D=50
analysis.max.sequence.count.PRINTS=250
analysis.max.sequence.count.PROSITE_PROFILES=500
analysis.max.sequence.count.PROSITE_PATTERNS=500
analysis.max.sequence.count.PIRSF=50
analysis.max.sequence.count.PRODOM=1000
analysis.max.sequence.count.SSF=50
analysis.max.sequence.count.PIRSFBLAST=1000
analysis.max.sequence.count.HAMAP=200
analysis.max.sequence.count.PFAM_A=5000
analysis.max.sequence.count.PFAM_B=5000
analysis.max.sequence.count.COILS=5000
analysis.max.sequence.count.COMPARA=1000
analysis.max.sequence.count.PHOBIUS=1000

# When loading a set of models / signatures into the database, include the abstract in the database.
signature.store.abstracts=false

# Stick bsub or qsub command on to the front of this:
worker.command=java -Xms32m -Xmx2048m -jar interproscan-5.jar
# This may be identical to the worker.command argument above, however you may choose to select
# a machine with a much larger available memory, for use when a StepExecution fails.
worker.high.memory.command=java -Xms32m -Xmx2048m -jar interproscan-5.jar

number.of.embedded.workers=2

# Spare worker creation
spare.worker.start.delay.seconds=120
spare.worker.repeat.interval.seconds=120

# If multiple hosts are sharing the same file system, a delay may be required to
# avoid stale NFS handles
nfs.delay.milliseconds=5000


# EBI Specific settings
ebi.uniparc.protein.load.size=1
ebi.uniparc.protein.load.start.delay.seconds=1
ebi.uniparc.protein.load.repeat.interval.seconds=1800000

precalculated.match.lookup.service.url=
delete.temporary.directory.on.completion=false

# JOB: jobLoadNucleicAcidSequence
getorf.minsize=50

#        600000 = 10 minutes
#        3600000 = 1 hour
#        7200000 = 2 hours
#        43200000 = 12 hours
