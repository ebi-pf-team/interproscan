# This is the InterProScan configuration file

# The text [UNIQUE], if present, will be replaced by a value unique to your running instance

# Temporary files used by the analyses will be placed in directories here:
temporary.file.directory.suffix=[UNIQUE]
temporary.file.directory=/tmp/${temporary.file.directory.suffix}


# The H2 database is copied by the standalone version of interproscan
i5.h2.database.original.location=work/template/interpro.zip
# LOCK_TIMEOUT: Sets the lock timeout (in milliseconds) for the current session
i5.database.connection.url=jdbc:h2:mem:interpro;LOCK_TIMEOUT=10000000

# Configure the version of perl to use when running member databases perl binaries
perl.command=perl

# Binary file locations
binary.hmmer3.hmmscan.path=bin/hmmer/hmmer3/hmmscan
binary.hmmer3.hmmsearch.path=bin/hmmer/hmmer3/hmmsearch
binary.hmmer2.hmmsearch.path=bin/hmmer/hmmer2/hmmsearch
binary.hmmer2.hmmpfam.path=bin/hmmer/hmmer2/hmmpfam
binary.fingerprintscan.path=bin/prints/fingerPRINTScan
binary.coils.path=bin/coils/ncoils
domainfinder3.path=bin/gene3d/DomainFinder3
binary.prodom.2006.1.prodomblast3i.pl.path=bin/prodom/2006.1/ProDomBlast3i.pl
# Note: Correct prosite binary distribution for your platform can be downloaded: ftp://ftp.expasy.org/databases/prosite/tools/ps_scan/
binary.prosite.psscan.pl.path=bin/prosite/ps_scan.pl
binary.prosite.pfscan.path=bin/prosite/pfscan
binary.panther.path=bin/panther/7.0/pantherScore.pl
binary.panther.perl.lib.dir=bin/panther/7.0/lib
binary.superfamily.1.75.ass3.pl.path=bin/superfamily/1.75/ass3_single_threaded.pl
binary.blastall.2.2.6.path=bin/blast/2.2.6/blastall
binary.blast.2.2.19.path=bin/blast/2.2.19
binary.getorf.path=bin/nucleotide/getorf
# Note: SignalP binary not distributed with InterProScan 5, please install separately e.g. in bin/signalp/4.0/signalp
binary.signalp.4.0.path=
# Note: TMHMM binary not distributed with InterProScan 5, please install separately e.g. in bin/tmhmm/2.0c/decodeanhmm
binary.tmhmm.path=
# Note: Phobius binary not distributed with InterProScan 5, please install separately e.g. in bin/phobius/1.01/phobius.pl
binary.phobius.pl.path.1.01=

# Member database model / data file locations (alphabetically sorted)
coils.new_coil.mat.path.2.2=data/coils/2.2/new_coil.mat
gene3d.hmm.path.3.5.0=data/gene3d/3.5.0/gene3d_classified.hmm
gene3d.model2sf_map.path.3.5.0=data/gene3d/3.5.0/model_to_family_map.csv
hamap.profile.models.path.201302.26=data/hamap/201302.26/hamap.prf
# It is IMPORTANT to set this temporary directory to a directory on LOCAL disk -
# network IO will slow the panther analysis down considerably.
panther.temporary.file.directory=/tmp/
panther.models.dir.7.2=data/panther/7.2/model
Pfam-A.hmm.path.27.0=data/pfam/27.0/Pfam-A.hmm
Pfam-A.seed.path.27.0=data/pfam/27.0/Pfam-A.seed
Pfam-A.hmm.path.26.0=data/pfam/26.0/Pfam-A.hmm
Pfam-A.seed.path.26.0=data/pfam/26.0/Pfam-A.seed
Pfam-C.path.27.0=data/pfam/27.0/Pfam-C
pirsf.hmm.bin.path.2.83=data/pirsf/2.83/sf_hmm.bin
pirsf.hmm.subf.bin.path.2.83=data/pirsf/2.83/sf_hmm_subf.bin
pirsf.hmm.path.2.83=data/pirsf/2.83/sf_hmm
pirsf.hmm.subf.path.2.83=data/pirsf/2.83/sf_hmm_subf
pirsf.dat.path.2.83=data/pirsf/2.83/pirsf.dat
pirsf.sf.tb.path.2.83=data/pirsf/2.83/sf.tb
pirsf.sf.seq.path.2.83=data/pirsf/2.83/sf.seq
prints.kdat.path.42.0=data/prints/42.0/prints42_0.kdat
prints.pval.path.42.0=data/prints/42.0/prints.pval
prints.hierarchy.path.42.0=data/prints/42.0/FingerPRINTShierarchy.db
prodom.ipr.path.2006.1=data/prodom/2006.1/prodom.ipr
prosite.models.path.20.89=data/prosite/20.89/prosite.dat
prosite.evaluator.models.path.20.89=data/prosite/20.89/evaluator.dat
signalp.4.0.perl.library.dir=bin/signalp/4.0/lib
# Note: Smart overlapping and threshold files not distributed with InterProScan 5, please install separately e.g. in data/smart/6.2
smart.hmm.path.6.2=data/smart/6.2/smart.HMMs
smart.hmm.bin.path.6.2=data/smart/6.2/smart.HMMs.bin
smart.overlapping.path.6.2=
smart.threshold.path.6.2=
superfamily.hmm.path.3.0=data/superfamily/1.75/hmmlib_1.75
superfamily.self.hits.path.1.75=data/superfamily/1.75/self_hits.tab
superfamily.cla.path.1.75=data/superfamily/1.75/dir.cla.scop.txt_1.75
superfamily.model.tab.path.1.75=data/superfamily/1.75/model.tab
superfamily.pdbj95d.path.1.75=data/superfamily/1.75/pdbj95d
tigrfam.hmm.path.13.0=data/tigrfam/13.0/TIGRFAMs_13.0_HMM.LIB
# Note: TMHMM model files not distributed with InterProScan 5, please install separately e.g. in data/tmhmm/model/2.0/TMHMM2.0.model
tmhmm.model.path=data/tmhmm/model/2.0/TMHMM2.0.model


#hmmer cpu options for the different jobs
hmmer3.hmmsearch.cpu.switch.pfama=--cpu 4
hmmer3.hmmsearch.cpu.switch.tigrfam=--cpu 4
hmmer3.hmmsearch.cpu.switch.gene3d=--cpu 4
hmmer3.hmmsearch.cpu.switch.superfamily=--cpu 4

hmmer2.hmmpfam.cpu.switch.smart=--cpu 3
hmmer2.hmmpfam.cpu.switch.pirsf=--cpu 8

#blastall cpu options
blastall.cpu.switch.pirsf=-a 8


# These values control the maximum number of proteins put through
# an analysis in one go - different algorithms have different optimum values.
# Note that if you suffer from out of memory errors, reducing these values
# will almost certainly help, but may reduce the speed of analysis.
analysis.max.sequence.count.SIGNALP=100
analysis.max.sequence.count.TMHMM=100
analysis.max.sequence.count.PANTHER=100
analysis.max.sequence.count.SMART=50
analysis.max.sequence.count.TIGRFAM_9=50
analysis.max.sequence.count.TIGRFAM_10=100
analysis.max.sequence.count.GENE3D=50
analysis.max.sequence.count.PRINTS=100
analysis.max.sequence.count.PROSITE_PROFILES=100
analysis.max.sequence.count.PROSITE_PATTERNS=100
analysis.max.sequence.count.PIRSF=50
analysis.max.sequence.count.PRODOM=100
analysis.max.sequence.count.SSF=50
analysis.max.sequence.count.PIRSFBLAST=100
analysis.max.sequence.count.HAMAP=100
analysis.max.sequence.count.PFAM_A=100
analysis.max.sequence.count.PFAM_B=100
analysis.max.sequence.count.COILS=100
analysis.max.sequence.count.COMPARA=100
analysis.max.sequence.count.PHOBIUS=100

# This beta release runs on a single machine, so there is no need for a delay.  Leave this as 0.
#nfs.delay.milliseconds=0

# Set the number of embedded workers to the number of processors that you would like to employ
# on the machine you are using to run InterProScan.
#number.of.embedded.workers=4

# By default, if the sequence already has matches available from the EBI, this service will look them
# up for you.  Note - at present it will always return all the available matches, ignoring any -appl options
# set on the command line.
precalculated.match.lookup.service.url=http://www.ebi.ac.uk/interpro/match-lookup

#proxy set up
precalculated.match.lookup.service.proxy.host=
precalculated.match.lookup.service.proxy.port=3128

# Instructs I5 to completely clean up after itself - leave set to true.
#delete.temporary.directory.on.completion=true

# A list of TCP ports that should not be used for messaging. (Apart from this, only ports > 1024 and < 65535 will be used.)
tcp.port.exclusion.list=3879,3878,3881,3882

# JOB: jobLoadNucleicAcidSequence
#getorf.minsize=50

# TRUE by default, which means all generated graphical output documents (only SVG at the moment) will be archived (using the Linux command tar).
# This simple switch allows you to switch the archive mode off (simply set it to FALSE).
archiveSVGOutput=true

worker.command=java -Xms32m -Xmx2048m -jar interproscan-5.jar
# This may be identical to the worker.command argument above, however you may choose to select
# a machine with a much larger available memory, for use when a StepExecution fails.
worker.high.memory.command=java -Xms32m -Xmx2048m -jar interproscan-5.jar

#grid name
grid.name=lsf
#grid.name=sge

#lsf/bsub commands
grid.lsf.worker.command=bsub -q production-rh6
grid.lsf.worker.high.memory.command=bsub -q production-rh6 -M 8192
grid.lsf.master.command=bsub -q production-rh6
grid.lsf.master.high.memory.command=bsub -q production-rh6 -M 8192

#sge qsub commands
grid.sge.worker.command=qsub -N i5t2worker
grid.sge.worker.high.memory.command=qsub -N i5t2hmworker
grid.sge.master.command=qsub -N i5t1worker
grid.sge.master.high.memory.command=qsub -N i5t1hmworker

#grid jobs limit
grid.jobs.limit=1000

#project name for this run  - use user.digest
user.digest=i5GridRun


#number of embedded workers  for the master
number.of.embedded.workers=4
maxnumber.of.embedded.workers=4

#number of embedded workers for the workers
worker.number.of.embedded.workers=2
worker.maxnumber.of.embedded.workers=2


#number of connections for the master
master.maxconsumers=120

max.tier.depth=2

#throttled net
grid.throttle=true
worker.maxunfinished.jobs=32

# Spare worker creation
spare.worker.start.delay.seconds=120
spare.worker.repeat.interval.seconds=120

# If multiple hosts are sharing the same file system, a delay may be required to
# avoid stale NFS handles
nfs.delay.milliseconds=5000


# EBI Specific settings
ebi.uniparc.protein.load.size=10000
ebi.uniparc.protein.load.start.delay.seconds=1
ebi.uniparc.protein.load.repeat.interval.seconds=1800000

delete.temporary.directory.on.completion=false

# JOB: jobLoadNucleicAcidSequence
getorf.minsize=50

#        600000 = 10 minutes
#        3600000 = 1 hour
#        7200000 = 2 hours
#        43200000 = 12 hours

#log4j file
log4j.log.file=i5.log4j.out.txt
log4j.jms.level=warn